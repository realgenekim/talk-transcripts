# John Carmack's Keynote: Quakecon 2013 part 4


* **Speaker: John Carmack**
* **Video: [https://www.youtube.com/watch?v=1PhArSujR_A](https://www.youtube.com/watch?v=1PhArSujR_A)**

[![Watch the video](https://img.youtube.com/vi/1PhArSujR_A/maxresdefault.jpg)](https://youtu.be/1PhArSujR_A)

(3 paragraphs on graphics engines deleted)

So my big software evolution over the last certainly three years and stretching back tendrils a little bit further than that has been this move towards functional programming style and pure functions. And it's been long enough now that I can really take some valid data points from it where I can look at some code, I just ran across this last week, I was looking through some code and I came across this file full of a bunch of reasonably sophisticated code that turned out we're not really using anymore. But it had just sat there completely innocuous, not bothering anybody and it had been written in this functional style where it was all self contained and I count that as a win.

And there's a number of things like that where you look at this and say, "Okay, this is a lot of complex, sophisticated code, but it's a pure function." It's just completely compartmentalized over here. You pass in stuff, you get out stuff and anybody that's not calling that function does not care whether that code exists or not and that could be contrasted with so much other code that has assumptions, and interactions, and tendrils throughout the system where there are so many things that you set a flag here, or you call this sub system to put it into this state so that something else that you're going to do later will interact with that in a different way.

And we have sort of the horror show of that right now is our build game code, the stuff that goes and you say build game for these maps. It sets all of these hooks and flags throughout our resource loading and file system to be able to get callbacks on these different things and then runs and starts up the map and there's different flags and console variables and it's just godawful. And it causes us problems on almost a weekly basis.

And I've got enough of these positive cases to stack up against this to say it's usually more of a pain to try and write something in this self-contained functional way. But if you're going to use the code for years, it has large advantages. I'm seeing the payoffs more and more as I, just on a regular basis, I see these wins where that's been happy and good because it was written in a pure form. That's been a real pain because it wasn't, because it used callbacks and tendrils and flags and settings and all these other ways of doing things. So I am more convinced than ever that it really is a big win.

So I've been applying this for years just the notion of functional purity in C++ in my day to day writing language. And I've gone and poked around at, looked at Haskell in different places, but I never wrote a significant amount of code. In the last year, I set out to go ahead and try and get sort of my 10,000 lines of code in real functional languages to try and get something that I can talk about their merits in a concrete sense rather than an abstract sense. And I had been... It was one of these things where I programmed just enough that I always had to go review the tutorials each time I did it. I'd go through the beginning Haskell tutorials, maybe three times where I'd go, I'd learn this, I'd write some code, come back six months later, forget all the ways to set up the imports, go through it again. But finally trying to write enough code to make it stick.

And the project that I set out to do on this was I wanted to do something that would be enough code to learn about the large systems, because when you look through exercises in books, they're toys. And there are a completely different set of things that you learn when you're looking at system scale versus exercise or toy scale. So it needed to be something with a little bit of meat on it and something that I could reference against other things that I've done.

So what I set out to do was take the original Wolfenstein 3D and reimplement it in Haskell. So I started off with loading the assets into there, which are in this godawful old format. Back when I was fitting things on floppy disks and I was re-inventing compression methods for myself. So it's some RLE on top of very badly bastardized, independently invented LZSS. This messy binary format, which you'd think, "Okay, maybe this isn't the greatest thing for implementing functional purity." But it turned out that that winds up being a lovely little bit of functional code to do that and it's a fraction of the size of the C code where you hear Haskellers and people talk about a 10th the size of equivalent code. And that's probably an exaggeration, but I believe that some of this nicely commented clean Haskell code can be a factor of a few smaller than the C++ code that I was boarding to.

I got to the point of having the guards on paths, walking around, running player movement at some basic levels, but I was finding that it's really difficult for me to work on something that's not work. I would pat myself on the back for tearing away and spending a whole hour on my Haskell research project every now and then and I couldn't hit it on a regular basis. It was just not, I couldn't make myself take the time. I mean I just have that internal itch that's like, "Oh, I could be doing something that's productive in the here and now." And then I know that it's good in the longterm, it's a character issue that makes it difficult for me on that.

So one of the things that happened then that was sort of a happy, good fortune is I'd always been poking around and one of the languages that I would look at, I settled on Haskell as probably my functional language of choice to follow up on. And I generally still agree that that's one of the strongest directions. I'm still not completely sold on the value of laziness. So the people that talk about ML derivatives, they might have a point. I haven't evaluated side by side, so there may be something there.

But one of the ones that I at least considered and rejected was Lisp. And Lisp has... There's a lot of history to Lisp. It's just about the second oldest in use language. It goes back to the '50s and I've always had in my head Lisp almost up on a pedestal. There are things like... A formative book in my teenage years was Hackers: Heroes of the Computer Revolution and a lot of that talked about the MIT computer crowd and you had the building of the Lisp machines, and the Lisp packers, and Richard Stallman's last days there and that stuck with me a lot.

And reading Paul Graham's essays, reading The UNIX-Haters Handbook and the people that would still talk about these old Lisp machines and the values of it. Oh and my favorite paper title now is, there is a paper by the people that became the racket scheme system and the subtitle on it is, revenge of the son of the Lisp machine. It was about programming language environments. I thought that was just fabulous for a paper subtitle. So I'd always had this sort of Lisp up on a bit of a pedestal and I thought, "Well, it'd be great to have deep Lisp knowledge." I've heard plenty of people say, "Oh, just learning the syntax, that's not going to do anything for you. You need to write enough code to sort of get the Zen of Lisp." And for years, for decades now I've thought, "Well that'd be nice, but I'd pay money if I could get the brain download to do that, but I just can't see myself ever having the time to do that." As witnessed by my trying to spend time on Haskell, I can't make myself spend that many... If I'm sitting at my workstation, I want to work on something that is relevant to the current project.

But what happened is, I found out that just poking around, I forget exactly how it came to my attention, but there is a tiny little Lisp development environment that you can get on the iPad called Lisping. And it's this sort of visual editor. It matches up all your parentheses and you couldn't write a real program in it, but you can write scheme in it, and go through and do exercises, and it shows you the arrangements, and it's kind of neat. I look at that as-

And the arrangements, and it's kind of neat, I look at that as, okay, the idea of visual programming has never really taken off. And we all still wonder whether at some point we can extract more of the structure of the programs beyond just syntax coloring and we can do useful things there, and Lisp with its nature of everything and S-expression and the homeiconicity of it has a lot going for it. And still this is a trivial program, but what I found out that was just magical to me is that I have my iPad with me, all of these times when I'm not at my workstation. And I found there were all of these little hours where I could be doing programming if it was on my iPad, because I'm at home sitting on the couch somewhere or I'm on an airplane or I'm stuck someplace. And I don't have my system, so I don't have that same personal guilt trip about not working on the work that I need to move towards the next milestone, and I could actually do some real programming.

So I picked up and I spent a decent amount of time learning Scheme, doing some work on the iPad, writing a few simple programs, write a K-D tree builder, write a parser for something. And eventually I did wind up with one of the grand old books of computer science. Structured Interpretation of Computer Programs, or SICKP there, and it's classic MIT text. It's for undergraduates. It's supposed to be sort of a first MIT course, but it uses Scheme as the programming language and it's one of those books up on a pedestal that are on the books every computer programmers should read. And I started going through, I took, I actually took some time off from work and said I'm going to do Lisp immersion. I'm going to spend this week doing nothing but Lisp programming. I'm not even going to think about working on what I should be working on.

And that worked. I was able to go in and clock a whole bunch of hours, and get to the point where I pretty much do get it. And I get some of the value from it, and so this undergraduate book, you'd think, okay, why is John Carmack reading an undergraduate textbook on computer programming? But there's value to be gotten in, you can find value in almost anything at that level. Any college textbook you pick up, you can probably get good value out of it, even if it's a topic that you already know. One of the things, I crossed some threshold in recent years where I've always loved sort of reading, grazing on technical stuff. I've always liked textbooks, reading them, light bedtime reading for whatever. But in recent years I've gotten to the point where I actually look forward to doing the exercises, and part of that's because getting older, you need a little bit of an extra push to make things stick in your brain. And I was talking with my stepfather who was an engineer I about that.

I mentioned that, he looks at me and says, he's pushing 70 he's like, "You have no idea, John." So I'm not sure I'm looking forward to the slow decline towards that. But working the exercises in the book is obviously useful. And the thing about this particular book where if you take your, learn language XXX in 24 hours, you just get these very practical little exercises. But here I'm going looking up, traveling through Wikipedia going, okay, what's an Ackerman function? What are these Church numerals and all of this math basis stuff that was kind of entertaining to learn while I'm learning the programming challenges along with it. So I do think that I sort of get Lisp now, and I have working ability in Haskell, and I've got a few conclusions coming from it. One of them is that there's still the question about Static versus Dynamic. And I know there was a survey just coming out recently where the majority of programmers are still really not behind Static typing. And I know there's the two orthogonal axis about whether types are strong or weak, and whether it's Static or Dynamic.

And I come down really pretty firmly and all of my experience continues to push me towards this way that strong static typing has really significant benefits. Sometimes it's not comfortable. Sometimes you have to build up a tight scaffolding to do something that should be really easy, but there are real strong wins to it. I see this in the code that causes us problems. In my toy stuff in recent months, in the Haskell stuff that I was doing, the one head-scratcher where I was looking at something going, what the heck is this doing? And I desperately wanted a real debugger, and Haskell does not have what I would consider a real debugger. The one thing that was there turned out to be the part of the data that was untyped when I was still looking at these two planes of data for the Wolfenstein data, and I just had them backwards and it was causing bizarre stuff there. That was the only thing that really had me baffled for a little while, was a case where proper typing would have removed that, if it was dealing with typing throughout it.

And conversely in the Lisp work, I had a bunch of cases where I was doing something that was just wrong because the types weren't there. If it was statically typed, it would've caught it ahead of time. Now I do see more of the charm now that I've had some experience with a Dynamic language, I see the lure, the enticement of having, just throw random types onto anything about not having to have sort of template typing arrangements and things. There's an appeal to that, but I think that it bites you in the end if the code lives a long time, and it grows enough. I think that the value of types is just super, super important, and that's something that's going to, it's a religious argument among programmers, and I despair a little bit about trying to win the arguments in a convincing empirical sense, because these do come down to these tendencies of programmers.

And if somebody's being belligerent about it, they can just say, "Well, I don't have those tendencies. " And I can say, as being a lead programmer over, a technical director over dozens and dozens of programmers, billions of lines of code. It's just amazing how many mistakes and how bad programmers can be. Everything that is syntactically legal that the compiler will accept will eventually wind up in your code base. And that's why I think that Static typing is so valuable because it cuts down on what can kind of make it past those hurdles there.

So I'm only getting stronger in my stance on the utility of Static typing, Static analysis. Don't let those things just kind of happen and get fixed up at runtime. So one of my, my sort of sneaky plan for turning the Haskell work on Wolfenstein into something that was going to tie into real work. It relates to a vision that I have for using multi-core and game logic in a different way than we're doing right now. So the state of where we're at right now with game code is that we run all the game code in one thread, because the idea of using locks to synchronize amongst all of our current game code was just absolutely terrifying. The heavyweight lifting stuff that we do with collision detection, pathfinding, a lot of the stuff that would take up tons of work, building extra particles, animating skeletons, all of that gets run off into jobs that are done with deferred calculations.

It's a pain to do things that way. You set it up, but it's understandable where a developer can just look at this and say, "Okay, I want to do this next frame. I'll set up my query. Please go trace these 50 things and I'll deal with it next frame." It adds all these extra flags and bookkeeping, but it's still a heck of a lot better than saying, "Oh, well, we're going to merrily run in parallel. I'm going to critical section some things." That way it leads to disaster. There's just no way that was going to work out.

But one of the things that I've been thinking might be possible is that the thing that I wanted to test on the Wolfenstein, and I didn't really get far enough on this to say for sure yet. I hope to follow up and continue it. And it's arguable that Wolfenstein's not enough to prove this one way or the other, but if you are running all of your actors or entities in the world, independently parallel, but it's functionally pure, they're past in a reference to a static copy of the world and themselves, they return their new version at the end. They can't break anybody else because they can't touch anything else. It's not allowed by the compiler. And that is, by the way, one of the things that I feel pretty strongly about. Why I went Haskell rather than some of the other perhaps more approachable languages. It's the brutal purity of it.

Languages talk about being multi-paradigm as if it's a good thing, but multi-paradigm means you can always do the bad thing if you feel you really need to, and programmers are extremely bad at doing sort of the timescale integration of the cost of doing something that they know is negative. I mean, everyone will know. It's like, oh, this global flag, this is not a good thing. This is a bad thing, but it's only a little bad thing. And they don't think about how the next five years, how many times that little bad thing is going to affect things. So brutal purity. You have no choice. You do not have an escape hatch. You do set bang and change something just because you feel this a really good thing and it's appropriate here. You just have no choice. Absolute purity.

And the way I had that all segmented is the little bit of monadic code that happens in the main thread is just one file. Everything else is absolutely pure functions. Not even any of the fancy things that can help you escape in some ways. But so while I was proving out this idea that, okay, entities running separately, you've got the obvious question. Well how do you shoot somebody if you can't affect them? You say, well I'm firing my gun. I hit him. The world says I do. I want to make him die. So you have to make an event of some kind that gets communicated to the other entity.

And now all game engines have some kind of event passing mechanisms. And in general, I don't encourage people using them, because it decouples the flow of control if you can do something. If you can do something right here, it's better to do it right here rather than have it done by some system elsewhere. But if you're in a pure functional mode, that's the only way you can wind up doing effects. And it turns out to actually be not that bad. One of the things that was one of those, wow, this is really...  ... that bad. One of the things that was one of those, "Wow, this is really clean in Haskell," is in tech five, and tech four for that matter, we have an event system where you can bundle up objects with different numbers of parameters and you've got issues with the typing and the number of parameters. It's this whole system for passing around these bundled events.

In Haskell, it's a partially evaluated function that just takes an entity as its parameter and returns another entity. There's no system for it. It's just built-in for the language. You can have a, "do damage" function. You partially evaluate it with your five points of damage that you're going to do and then you pass it so that it's just going to take the last function parameter as the entity, and you set that up on your own personal list. So, every entity makes a list of all of the things that they're going to do to anybody.

And then at the beginning of the next frame, you go and you gather everything together. You distribute all of that to the entities. The first thing they do, they've got the world, they've got the list of all the events that affect them from anybody else. They apply all of those one after another, generating a new copy of themselves as they go. Then they do their thinking and their processing and generate the final version that goes back into the world. With this sort of method there are coherence. Nothing gets out of because everything sort of happens at the same time.

There is no sense of time ordering, but you do have the question of, since everybody's looking at the previous frames' rendering, two people approach a narrow hallway. They both say they want to go into that hallway. They both think it's clear. So they both go into it and then, "Well, what do you do next frame?" They both say, "Well, I'm here. But two people wound up at the same place." So there's a little bit of resolving that has to be done there.

And I haven't worked all of this out, but I'm completely satisfied that it's possible that you wind up giving some precedents on their use, physical repulsion rather than absolute surface collisions on there. It can all be worked out. This was my approach in Haskell, this was what I was building there and it seemed to be working out well. It may yet fall apart on something harder. But I had to pick a research project that I could conceivably do, even if I haven't managed to finish it yet. If I had picked Doom 3, there's just no way I would've personally been able to go through and do this.

But my sneaky plan to justify all of this as actually being a really good idea was that while in C++ the idea of using everybody running the way the code is right now would not work, it'd be awfully crashing and would have race conditions and it would just be terrible. But if you would code sort of in this style of, you do your object from beginning to end, you could look at everybody else, but you can't touch anybody else and you could do everything theoretically.

All the stuff that we differ right now, the traces against the world, the animating your pose, the building your particles that tie on all that. Suff that as long as it didn't take more than one entire frame, 16 milliseconds, you could have straight line, pleasant, beautiful linear code that would be clear and simple and easy to step through, tell what's going on, not this mess of deferred and handed off to different subsystems, queried to later frames. You could make code that would be nice again. It would be code that looks like Quake 1, 2, 3, where you can just say, "You start here, you go through, you do all of this and you're done."

That would be a really powerful thing for game development. If we could make game development twice as easy on the game programming side, we'd have twice the iteration time, get games done in half the time. It would be a huge, huge win to make some... it doesn't have to be an order of magnitude, but a factor of two would be monumental. What my thought was is that "Okay, we can't have things that just randomly look around at all this." Even if you say you're programming in this look only way, but if your pointers let you point at somebody, again, if it's syntactically legal, it will make it into the code base. It would be almost impossible to guard against. My Scheme is instead of taking just your single heap here, go ahead and pretend you're... Actually, do garbage collection, which is another thing that garbage collection is a benefit for developers. It has a bad name, a bad reputation in game development for intermittent pauses. Intermittency is bad. A fixed overhead we can deal with and it makes programming easier. And programming is often the long pole in the tent for getting games done. Anything we can do to make this easier to spend our performance is going to be a useful thing.

You set everything up, you garbage collect every frame so you make a pass through all the objects in your gaming. It's going to take discipline to make sure that none of the big things stay in the game. That you put all of your assets, resources separately managed, but the game stuff, you have it in the heap. You can make a walkthrough at every frame. So it's this fairly standard, sort of compacting or broken hearts garbage collection where you pass through, you copy over the stuff that you still need to the next frame. It takes twice as much space for your heap.

But the game heap, if you isolate out all of the constant data and all of the big media, it's not that large. I can guarantee that our real mutable data, it's encountered in megs, not tens of megs, and it's probably only a few megs, so it's completely credible to walk it every frame. So you walk through the entire frame, you compact and copy and garbage collect to another frame, but you keep the old frame there and your memory protect it. And when you're fixing up all of these pointers, as you're doing the garbage collection, you're marking pointers on whether they're in use, whether you've copied them over.

But each entity keeps its own pointers to itself, but any point that it has to something else, points to the frame that was just memory protected, that was garbage collected from. So any pointer that you get is either going to point to your state, which is mutable, or if it's pointed to anything else, it's pointing to a static copy. So you will bus error if you try to access that, it will be hard protected. It's not possible to sneak in something that's going to be a race condition.

And I think that under those conditions you get garbage collection, which is a programming when you get the D threading of all of these things that we do for performance reason, you allow it to run all of these things in parallel. So we get more scalability as we go up to dozens and dozens of cores. And I think it could be a really huge win, but it's a research project. It's not something that I can sort of roll into the current code base, but I look at it and think it's not ridiculous that it could be migrated towards and it would have some large benefits.

That's one of my sneaky schemes for wanting to kind of move the state of the programming forward there. But there's several things that need to happen before that can really come to fruition. Some of the other things that are appealing about lists is... Related to programming the game stuff, I have been scratching my head a little bit in recent months thinking that when I look back at Quake 1 with... I did QuakeC, and that was me just totally winging it on language design. "Okay, I've got C-format expressions in one object type that goes across. That's the only thing you use for all of it."

And it was certainly a huge success. There were lots of people that learned programming so they could do QC and make mods for it, and it's had a positive impact on the way the industry's gone and people that have got into it. But now I really do kind of wonder what would have been the divergent road if it had been Quake Scheme instead of QuakeC. Scheme in the small version of Lisp is one of those things that the language is it is extremely elegant and concise.

And when you really sort of get that all you need is this parameter substitution in there and you can do everything from that, there's a majesty to that abstraction that's pretty powerful and it has all the damn parentheses and it has prefixed notation of these things that people, professional programmers that are used to working in C are not comfortable being shown a bunch of Lisp.

There are arguments, I'm not sure... There are statements, I'm not sure that I believe them that novice people that have never programmed before take quickly to functional programming as declarative programming. That doesn't quite ring true to me. I think that might be some selection bias that maybe the MIT undergraduates that say they've never programmed do as well when presented a functional programming language, but there is a lot to be said for the imperative nature of you explain computer programming by, "You do this, you do this. If this, you do this, otherwise you do that."

From teaching my seven-year-old and eight-year-old, I think that it's... I think that there is a value to the imperative nature there, but I do wonder if we had had a more potent language there. If we had used something like Scheme, what more could have been accomplished there that wasn't in the nature of just QuakeC? An idle thought were for embedding, for doing a big application. I think Haskell is just a superior language for what you'll get out of it than Lisp.

There are lots of times I was doing Lisp code and I was thinking, "This would be shorter and clearer in Haskell." certainly the typing is, it is a huge, huge thing, but for small things, for an embedded language like what QuakeC was, There's a lot of advantage to Scheme, at least, it's so tiny. You can make it very, very small and yet still have kind of complete power. You can in theory do anything with even the simplest of schemes there. So using it for an embedded language is still appealing for me and I've sort of still got my eye open for, "Where could I use this in some way?"

Because in the end, while I wouldn't do application development in it, I found it charming in a way that's sort of maybe difficult to convey to especially non-programmers, but it is this very, very old language that is still-
